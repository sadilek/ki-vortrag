{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Was ist KI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. ChatGPT\n",
    "\n",
    "ChatGPT: “KI steht für künstliche Intelligenz, ein Bereich der Informatik, der sich darauf konzentriert, Maschinen oder Computersysteme zu erschaffen, die Aufgaben ausführen können, die normalerweise menschliche Intelligenz erfordern. Dies umfasst eine breite Palette von Fähigkeiten wie Problemlösung, Spracherkennung, Lernen, Planung und Wahrnehmung.”\n",
    "\n",
    "### 1.2. Einordnung\n",
    "\n",
    "<img src=\"ki.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regel-basierte und statistische KI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Prinzip EVA\n",
    "\n",
    "<img src=\"eva.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport lib\n",
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.plot_f(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    return x**2\n",
    "\n",
    "\n",
    "lib.plot_f(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Regel-basierte \"KI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bewertung(text):\n",
    "    if \"nicht super\" in text:\n",
    "        return \"schlecht\"\n",
    "    if \"super\" in text:\n",
    "        return \"gut\"\n",
    "    if \"nicht schlecht\" in text or \"nicht doof\" in text:\n",
    "        return \"gut\"\n",
    "    if \"schlecht\" in text or \"doof\" in text:\n",
    "        return \"schlecht\"\n",
    "    return \"unsicher\"\n",
    "\n",
    "\n",
    "(\n",
    "    bewertung(\"Der Film war super.\"),\n",
    "    bewertung(\"Der Film war schlecht.\"),\n",
    "    bewertung(\"Der Film war nicht super.\"),\n",
    "    bewertung(\"Der Film war nicht schlecht.\"),\n",
    "    bewertung(\"Verrückt ist, wer sagt, der war super.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Tensoren – Einzelwerte, Listen, Tabellen, ..., hochdimensionale Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor(9)\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([9])\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([9, 10, 11, 12])\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[9, 10, 11, 12], [12, 13, 14, 15], [13, 14, 15, 16]])\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.stack([a, a * 2])\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.stack([b, b + 5])\n",
    "c, c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Statistische KI zur Bilderkennung – MNIST, das \"Hallo Welt\" des ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hallo Welt!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "(train_X, train_y, test_X, test_y) = (\n",
    "    torch.tensor(train_X),\n",
    "    torch.tensor(train_y),\n",
    "    torch.tensor(test_X),\n",
    "    torch.tensor(test_y),\n",
    ")\n",
    "train_X = train_X / 255\n",
    "test_X = test_X / 255\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show(nr):\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(nr, cmap=plt.get_cmap(\"gray\"))\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    show(train_X[i])\n",
    "    plt.title(str(train_y[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_3 = train_X[train_y == 3].mean(dim=0)\n",
    "show(mean_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "show(test_X[0])\n",
    "plt.subplot(1, 2, 2)\n",
    "show(test_X[0] * mean_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.stack([train_X[train_y == i].mean(dim=0) for i in range(10)])\n",
    "mean = mean / mean.sum(dim=(1, 2), keepdim=True)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    show(mean[i])\n",
    "    plt.title(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 3\n",
    "for i in range(10):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    show((mean[i] * test_X[sample]))\n",
    "    plt.title(\"%d: %.3f\" % (i, torch.sum(mean[i] * test_X[sample])))\n",
    "plt.subplot(3, 4, 12)\n",
    "show(test_X[sample])\n",
    "plt.title(str(test_y[sample].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_digit(sample):\n",
    "    return (mean * sample).sum(axis=(1, 2))\n",
    "\n",
    "\n",
    "classify_digit(test_X[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification = torch.stack(\n",
    "    [classify_digit(sample).argmax() for sample in test_X]\n",
    ")\n",
    "test_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification == test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (test_classification == test_y).float().mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Maschinelles Lernen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Funktionen mit Parametern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "\n",
    "def f1(x):\n",
    "    return f(x, 3, 2, 2)\n",
    "\n",
    "\n",
    "def f2(x):\n",
    "    return f(x, 2, 5, 1)\n",
    "\n",
    "\n",
    "lib.plot_f(f1)\n",
    "lib.plot_f(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Gradientenverfahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(1)\n",
    "n = 20\n",
    "y = torch.randint(0, 2, (n,))\n",
    "X = torch.randn(n)\n",
    "X[y == 1] += 2\n",
    "graph = sns.swarmplot(x=X[:].numpy(), hue=y.numpy())\n",
    "graph.axvline(x=0.5, color=\"red\")\n",
    "print(\"Anzahl orangene Punkte: %d\" % y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, threshold):\n",
    "    return (X > threshold).int()\n",
    "\n",
    "\n",
    "classify(X, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = torch.linspace(-2, 4, 1000)\n",
    "errors = [(classify(X, threshold) != y).sum().item() for threshold in thresholds]\n",
    "sns.lineplot(x=thresholds.numpy(), y=errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, threshold):\n",
    "    return X - threshold\n",
    "\n",
    "\n",
    "def loss(y_pred, y):\n",
    "    return (y - y_pred) ** 2\n",
    "\n",
    "\n",
    "loss(classify(X, 0.5), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [loss(classify(X, threshold), y).mean().item() for threshold in thresholds]\n",
    "sns.lineplot(x=thresholds.numpy(), y=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = (y - y_pred) ** 2\n",
    "# loss = (y - X - threshold) ** 2\n",
    "# loss = (z - threshold) ** 2\n",
    "# loss = z**2 - 2 * z * threshold + threshold**2\n",
    "# loss' = dloss/dthreshold = -2 * z + 2 * threshold\n",
    "# loss' = 2 * (threshold - |z|)\n",
    "# loss' = 2 * (threshold - |y - X|)\n",
    "\n",
    "\n",
    "def draw_with_slope(t):\n",
    "    loss_t = loss(classify(X, t), y).mean()\n",
    "    slope = 2 * (t - torch.abs((y - X).mean()))\n",
    "    sns.lineplot(x=thresholds.numpy(), y=losses)\n",
    "    plt.plot(t, loss_t, \"ro\")\n",
    "\n",
    "    def x_for_y(y):\n",
    "        return (y - loss_t) / slope + t\n",
    "\n",
    "    ts = torch.linspace(max(x_for_y(0), -2), min(x_for_y(12), 4), 100)\n",
    "    slopes = slope * (ts - t) + loss_t\n",
    "    plt.plot(ts, slopes, \"r--\")\n",
    "    return slope\n",
    "\n",
    "\n",
    "draw_with_slope(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = draw_with_slope(t)\n",
    "t = t - 0.1 * slope\n",
    "slope, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Ein einzelnes Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([0.1, 0.2, 0.3, 0.2])\n",
    "W = torch.tensor([1.0, -2.0, -1.0, 2.0])\n",
    "b = torch.tensor([0.5])\n",
    "input[0] * W[0] + input[1] * W[1] + input[2] * W[2] + input[3] * W[3] + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W @ input + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.relu(W @ input + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.plot_f(torch.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([0.1, 0.2, 0.3, 0.2])\n",
    "W = torch.tensor([[1.0, -2.0, -1.0, 2.0]])\n",
    "b = torch.tensor([0.5])\n",
    "lib.plot_network(input, [[W, b]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Mehrere Neuronen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([0.1, 0.2, 0.3, 0.2])\n",
    "W = torch.tensor([[1.0, -2.0, -1.0, 2.0], [2.0, -1.0, 1.0, -2.0]])\n",
    "b = torch.tensor([0.5, -0.1])\n",
    "lib.plot_network(input, [[W, b]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Mehrere Schichten = Neuronales Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn(16, 784)\n",
    "b1 = torch.randn(16)\n",
    "W2 = torch.randn(16, 16)\n",
    "b2 = torch.randn(16)\n",
    "W3 = torch.randn(10, 16)\n",
    "b3 = torch.randn(10)\n",
    "\n",
    "lib.plot_network(test_X[3], [[W1, b1], [W2, b2], [W3, b3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X):\n",
    "    X = torch.relu(X @ W1.T + b1)\n",
    "    X = torch.relu(X @ W2.T + b2)\n",
    "    X = X @ W3.T + b3\n",
    "    return X\n",
    "\n",
    "\n",
    "output = forward(train_X.reshape([-1, 784]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def loss(y_pred, y):\n",
    "    return F.cross_entropy(y_pred, y)\n",
    "\n",
    "\n",
    "loss(output, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_xs = []\n",
    "W1.requires_grad = True\n",
    "b1.requires_grad = True\n",
    "W2.requires_grad = True\n",
    "b2.requires_grad = True\n",
    "W3.requires_grad = True\n",
    "b3.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "k = 0\n",
    "batch_size = 256\n",
    "epochs = 1\n",
    "for i in range(epochs * len(train_X) // batch_size):\n",
    "    W1.grad = None\n",
    "    b1.grad = None\n",
    "    W2.grad = None\n",
    "    b2.grad = None\n",
    "    W3.grad = None\n",
    "    b3.grad = None\n",
    "\n",
    "    start = j * batch_size + k\n",
    "    end = (j + 1) * batch_size + k\n",
    "    j = j + 1\n",
    "    if ((j + 1) * batch_size + k) > len(train_X):\n",
    "        j = 0\n",
    "        k += 1\n",
    "        if k >= batch_size:\n",
    "            k = 0\n",
    "    loss_value = loss(\n",
    "        forward(train_X[start:end].reshape([-1, 784])), train_y[start:end]\n",
    "    )\n",
    "    loss_value.backward()\n",
    "\n",
    "    lr = 0.1\n",
    "    with torch.no_grad():\n",
    "        W1 -= lr * W1.grad  # type: ignore\n",
    "        b1 -= lr * b1.grad  # type: ignore\n",
    "        W2 -= lr * W2.grad  # type: ignore\n",
    "        b2 -= lr * b2.grad  # type: ignore\n",
    "        W3 -= lr * W3.grad  # type: ignore\n",
    "        b3 -= lr * b3.grad  # type: ignore\n",
    "\n",
    "    train_losses.append(loss_value.item())\n",
    "\n",
    "test_xs.append(len(train_losses) - 1)\n",
    "test_losses.append(loss(forward(test_X.reshape([-1, 784])), test_y).item())\n",
    "test_accuracies.append(\n",
    "    (forward(test_X.reshape([-1, 784])).argmax(dim=1) == test_y).float().mean().item()\n",
    ")\n",
    "\n",
    "sns.lineplot(x=range(len(train_losses)), y=train_losses).set(yscale=\"log\")\n",
    "sns.lineplot(x=test_xs, y=test_losses)\n",
    "sns.lineplot(x=test_xs, y=test_accuracies, ax=plt.twinx(), color=\"red\")  # type: ignore\n",
    "train_losses[-1], test_losses[-1], test_accuracies[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(test_X[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(W1[0].reshape(28, 28).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.zeros(784)\n",
    "input.requires_grad = True\n",
    "output = torch.zeros(10)\n",
    "output[3] = 1\n",
    "show(input.detach().reshape(28, 28))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "loss(forward(input), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    input.grad = None\n",
    "\n",
    "    loss_value = loss(forward(input), output)\n",
    "    loss_value.backward()\n",
    "    losses.append(loss_value.item())\n",
    "\n",
    "    lr = 0.0001\n",
    "    with torch.no_grad():\n",
    "        input -= lr * input.grad  # type: ignore\n",
    "\n",
    "show(input.reshape(28, 28).detach().numpy())\n",
    "loss(forward(input), output), forward(input), input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_X[1] + 1.1 * input.reshape(28, 28).detach().numpy()\n",
    "show(test_input)\n",
    "output = forward(test_input.reshape(784))\n",
    "output, output.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GPT = Generative Pretrained Transformer\n",
    "\n",
    "- Generative = Es wird Text erzeugt.\n",
    "- Pretrained = Das Netzwerk wird mit _viel_ Text trainiert, der nicht von Menschen vorverarbeitet wurde.\n",
    "- Transfomer = Eine spezielle Netzwerkarchitektur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/german-gpt2\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"dbmdz/german-gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(\"Die Katze springt\", return_tensors=\"pt\")\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.lookup_tokens(tokenizer, input.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.lookup_tokens(tokenizer, tokenizer(\"dx1p2f1\", return_tensors=\"pt\").input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(\"Die Katze springt\", return_tensors=\"pt\")\n",
    "output = model(**input)\n",
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = output.logits[0, 2].softmax(-1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices = probs.topk(5).indices\n",
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_indices:\n",
    "    print(\n",
    "        \"%5d – %.1f%% – %s\"\n",
    "        % (\n",
    "            i.item(),\n",
    "            probs[i].item() * 100,\n",
    "            lib.lookup_tokens(tokenizer, i.item()),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_next_words(text):\n",
    "    input = tokenizer(text, return_tensors=\"pt\")\n",
    "    output = model(**input)\n",
    "    probs = output.logits[0, -1].softmax(-1)\n",
    "    top_indices = probs.topk(5).indices\n",
    "    for i in top_indices:\n",
    "        print(\n",
    "            \"%5d – %5.2f%% – %s\"\n",
    "            % (\n",
    "                i.item(),\n",
    "                probs[i].item() * 100,\n",
    "                lib.lookup_tokens(tokenizer, i.item()),\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_next_words(\"Die Katze springt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_next_words(\"Das Auto springt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_next_words(\"Der Mann ist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_next_words(\"Der Frau ist es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Embeddings: Worte im Raum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"embedding.svg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.get_input_embeddings().weight\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedOf(word):\n",
    "    ids = tokenizer(\" \" + word).input_ids\n",
    "    assert len(ids) == 1\n",
    "    return embeddings[ids[0]]\n",
    "\n",
    "\n",
    "embedOf(\"König\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_similar(embedding):\n",
    "    distances = embeddings @ embedding\n",
    "    top_indices = distances.topk(5).indices\n",
    "    print(top_indices)\n",
    "    for i in top_indices:\n",
    "        print(\n",
    "            \"%5d – %5.2f – %s\"\n",
    "            % (\n",
    "                i.item(),\n",
    "                distances[i].item(),\n",
    "                lib.lookup_tokens(tokenizer, i.item()),\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "print_most_similar(embedOf(\"König\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_most_similar(embedOf(\"König\") - embedOf(\"Mann\") + embedOf(\"Frau\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_most_similar(embedOf(\"Berlin\") - embedOf(\"Deutschland\") + embedOf(\"Frankreich\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Meilensteine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2012**: AlexNet gewinnt ImageNet competition\n",
    "- **2013**: Reinforcement Learning spielt Atari Spiele\n",
    "- **2016**: AlphaGo gewinnt gegen Lee Sedol\n",
    "- **Spracherkennung**: Übergang von mehrschrittiger Verarbeitung (Phonemerkennung zu Worterkennung) zu - Ende-zu-Ende NN ML\n",
    "- **NLP**: Übergang von linguistischen Regeln zu NN ML\n",
    "- **2017**: Transformers für Übersetzungen\n",
    "- **2018**: BERT und GPT-1\n",
    "- **2018 + 2020**: AlphaFold\n",
    "- **2021**: DALL-E\n",
    "- **2022**: ChatGPT launch\n",
    "- **2023**: GPT-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Ausblick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"benchmarks.png\" />\n",
    "\n",
    "- KI wird bei immer mehr Aufgaben\n",
    "  - so gut wie ein durchschnittlicher Mensch\n",
    "  - besser als ein durchschnittlicher Mensch\n",
    "  - besser also der beste Mensch\n",
    "- Daniel Kahnemann: System 1 und System 2 Denken\n",
    "- KI arbeitet im Moment hauptsächlich wie System 1\n",
    "- System 2 als Heuristik on-top, meist Baumsuche\n",
    "- Menschliches Gehirn: 100 Mrd. Neuronen verbunden mit 100 Billionen Synapsen\n",
    "- GPT-4: Vermutet ~1 Billion Gewichte\n",
    "- AGI (Artifical General Intelligence) in den nächsten 2 - 10 Jahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "dot = graphviz.Digraph()\n",
    "dot.node_attr.update(shape=\"box\")\n",
    "\n",
    "dot.edge(\"KI\", \"Regel-basiert\")\n",
    "dot.edge(\"KI\", \"Statistisch\")\n",
    "dot.edge(\"KI\", \"Maschinelles Lernen\")\n",
    "\n",
    "dot.edge(\"Maschinelles Lernen\", \"Verstärkungslernen\")\n",
    "dot.edge(\"Maschinelles Lernen\", \"Unüberwachtes Lernen\")\n",
    "dot.edge(\"Maschinelles Lernen\", \"Überwachtes Lernen\")\n",
    "\n",
    "dot.edge(\"Unüberwachtes Lernen\", \"Clustering\")\n",
    "dot.edge(\"Unüberwachtes Lernen\", \"Dimensionsreduktion\")\n",
    "\n",
    "dot.edge(\"Überwachtes Lernen\", \"Entscheidungsbäume\")\n",
    "dot.edge(\"Überwachtes Lernen\", \"Support Vector Machines\")\n",
    "dot.edge(\"Überwachtes Lernen\", \"(Tiefe) Neuronale Netze\")\n",
    "\n",
    "dot.node(\"KI\", fillcolor=\"lightgreen\", style=\"filled\")\n",
    "dot.node(\"Regel-basiert\", fillcolor=\"#fcc\", style=\"filled\")\n",
    "dot.node(\"Statistisch\", fillcolor=\"#fcc\", style=\"filled\")\n",
    "dot.node(\"Maschinelles Lernen\", fillcolor=\"lightgreen\", style=\"filled\")\n",
    "dot.node(\"Verstärkungslernen\", fillcolor=\"lightgray\", style=\"filled\")\n",
    "dot.node(\"Überwachtes Lernen\", fillcolor=\"lightgreen\", style=\"filled\")\n",
    "dot.node(\"(Tiefe) Neuronale Netze\", fillcolor=\"#f77\", style=\"filled\")\n",
    "\n",
    "dot.render(\"ki\", format=\"svg\", cleanup=True)\n",
    "display(SVG(filename=\"ki.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "dot = graphviz.Digraph()\n",
    "\n",
    "dot.edge(\"Eingabe\", \"Verarbeitung\")\n",
    "dot.edge(\"Verarbeitung\", \"Ausgabe\")\n",
    "\n",
    "dot.node(\"Verarbeitung\", fillcolor=\"#f77\", style=\"filled\", shape=\"box\")\n",
    "\n",
    "# from left to right\n",
    "dot.graph_attr.update(rankdir=\"LR\")\n",
    "\n",
    "dot.render(\"eva\", format=\"svg\", cleanup=True)\n",
    "display(SVG(filename=\"eva.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin = [0.1, 0.2]\n",
    "deutschland = [0.2, 0.3]\n",
    "paris = [0.2, 0.1]\n",
    "frankreich = [0.3, 0.2]\n",
    "\n",
    "\n",
    "def plot_dot(coord, label, color):\n",
    "    plt.plot(coord[0], coord[1], color + \"o\")\n",
    "    plt.text(coord[0], coord[1], label)\n",
    "\n",
    "\n",
    "def plot_arrow(start, end, head_width=0.005):\n",
    "    plt.arrow(\n",
    "        start[0],\n",
    "        start[1],\n",
    "        end[0] - start[0] - head_width * 1.5,\n",
    "        end[1] - start[1] - head_width * 1.5,\n",
    "        head_width=head_width,\n",
    "    )\n",
    "\n",
    "\n",
    "plot_dot(berlin, \"Berlin\", \"r\")\n",
    "plot_dot(deutschland, \"Deutschland\", \"b\")\n",
    "plot_dot(paris, \"Paris\", \"r\")\n",
    "plot_dot(frankreich, \"Frankreich\", \"b\")\n",
    "plot_arrow(berlin, deutschland)\n",
    "plot_arrow(paris, frankreich)\n",
    "\n",
    "plt.savefig(\"embedding.svg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
